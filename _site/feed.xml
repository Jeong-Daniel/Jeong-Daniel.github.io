<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-06-17T16:34:30+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Data scientist’s room</title><subtitle>[&quot;Welcome to the Data Scientist&apos;s Room. I am posting blogs to deal with technical theories and field applications.&quot;]</subtitle><entry><title type="html">데이터와 모델의 편향(bias)과 분산(variance)</title><link href="http://localhost:4000/jekyll/update/2021/12/28/%ED%8E%B8%ED%96%A5(bias)%EA%B3%BC-%EB%B6%84%EC%82%B0(variance).html" rel="alternate" type="text/html" title="데이터와 모델의 편향(bias)과 분산(variance)" /><published>2021-12-28T00:38:46+09:00</published><updated>2021-12-28T00:38:46+09:00</updated><id>http://localhost:4000/jekyll/update/2021/12/28/%ED%8E%B8%ED%96%A5(bias)%EA%B3%BC%20%EB%B6%84%EC%82%B0(variance)</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2021/12/28/%ED%8E%B8%ED%96%A5(bias)%EA%B3%BC-%EB%B6%84%EC%82%B0(variance).html"><![CDATA[<p><strong><a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">편향과 분산의 트레이드오프 위키 URL</a></strong> 데이터 과학을 공부하고 기계학습(Machine Learning)을 다루다보면 한번쯤은 편향(bias)과 분산(variance에 대해서 만나게 됩니다. 제가 컴퓨터공학과에서 들었던 인공지능 수업에서도 교수님께서 설명을 하실때 가끔 데이터와 모델의 편향과 분산을 섞어 말하시고 나중에 정정하는 것을 보면서 이참에 정리를 해보고자 합니다.</p>

<h2 id="1-편향bias">1. 편향(bias)</h2>
<p><strong>데이터</strong>의 편향은 얼마나 데이터가 골고루 분포하는가 입니다. 예를 들어서 이상탐지등의 경우 전체 데이터에서 이상치의 비중은 매우 낮으며 이런 데이터를 가지고 그대로 학습을 할 경우 모델의 정확도를 담보할 수 없습니다. 이때 언더/오버샘플링 등을 통해서 보정을 합니다.</p>

<p><strong>머신러닝</strong>의 편향은 예측값과 실제값 간의 차이를 뜻합니다. 모델 학습시 여러 데이터를 사용하고 반복해서 새로운 모델로 학습하면 예측값들의 범위를 확인할 수 있고 편향은 이 예측값 들의 범위가 정답과 얼마나 멀리 있는지 측정합니다.</p>

<h2 id="2-분산varience">2. 분산(Varience)</h2>
<p><strong>데이터</strong>의 분산은 중심을 측정한뒤 샘플 데이터와 모집단의 데이터가 중심으로 부터 얼마나 분산되어 있는지 확인합니다. 이때 측정하는 방법은 여러가지가 있으며 분산은 편차제곱을 모두 더한뒤 편차 제곱의 평균을 구한 것입니다. 분산 값이 클 수록 데이터가 중심으로부터 떨어졌다는 의미</p>

<p><strong>머신러닝</strong>의 분산은 데이터로 학습한 모델이 예측한 값의 변동성을 뜻하며 만약 여러 모델로 학습을 반복한다고 가정하면 분산은 학습된 모델별로 예측한 값들의 차이를 측정</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><category term="Machine_Learning" /><summary type="html"><![CDATA[편향과 분산의 트레이드오프 위키 URL 데이터 과학을 공부하고 기계학습(Machine Learning)을 다루다보면 한번쯤은 편향(bias)과 분산(variance에 대해서 만나게 됩니다. 제가 컴퓨터공학과에서 들었던 인공지능 수업에서도 교수님께서 설명을 하실때 가끔 데이터와 모델의 편향과 분산을 섞어 말하시고 나중에 정정하는 것을 보면서 이참에 정리를 해보고자 합니다.]]></summary></entry></feed>